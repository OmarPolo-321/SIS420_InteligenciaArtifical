{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#https://www.kaggle.com/datasets/cristiangarcia/pointcloudmnist2d?select=train.csv\n",
        "'''\n",
        "Point Cloud Mnist 2D,\n",
        "'''"
      ],
      "metadata": {
        "id": "uchzHxI5-qed"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D_in, H, D_out = 1053, 150, 10\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")"
      ],
      "metadata": {
        "id": "Vw2MCHeIFVps"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(torch.randn(64, 1053))\n",
        "outputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dztzxcpaFaDt",
        "outputId": "3f6b280b-d223-4358-a98b-32f276d00a8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Point Cloud Mnist 2D,\n",
        "'''\n",
        "#https://www.kaggle.com/datasets/cristiangarcia/pointcloudmnist2d?select=train.csv\n",
        "import numpy as np\n",
        "data= np.loadtxt('/content/train.csv', delimiter=',',skiprows=1)\n",
        "# Divide las columnas en X (características) y Y (etiquetas)\n",
        "X, Y =data[:,1:],data[:,0]\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SQqcn3t8hcb",
        "outputId": "03de3540-f468-4949-a704-b1f4ac8af739"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 1053)\n",
            "(60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhd13ZFVF3aF",
        "outputId": "5db54575-f047-44b2-f422-908ce1684285"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5. 0. 4. ... 5. 6. 8.]\n",
            "[[ 17.  10. 249. ...  -1.  -1.  -1.]\n",
            " [ 22.  17.  50. ...  -1.  -1.  -1.]\n",
            " [  8.  12. 207. ...  -1.  -1.  -1.]\n",
            " ...\n",
            " [ 14.  13. 253. ...  -1.  -1.  -1.]\n",
            " [ 10.  14. 253. ...  -1.  -1.  -1.]\n",
            " [  7.   6. 254. ...  -1.  -1.  -1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalización y split\n",
        "\n",
        "#X_train = X[:7000] / 255.,\n",
        "#X_test=X[7000:] / 255.,\n",
        "#y_train= Y[:7000].astype(np.int)\n",
        "#y_test = Y[7000:].astype(np.int)\n",
        "X_train, X_test, y_train, y_test = X[:50000] / 255., X[50000:] / 255., Y[:50000].astype(np.int), Y[50000:].astype(np.int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvxpURc7AYG4",
        "outputId": "a360e8a9-98a9-43e9-b289-259de7882386"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-9771e080d068>:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  X_train, X_test, y_train, y_test = X[:50000] / 255., X[50000:] / 255., Y[:50000].astype(np.int), Y[50000:].astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "BsWXsHmQ-KSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# función de pérdida y derivada\n",
        "def softmax(x):#usada en la conversion de puntajes y el uso de probabilidades\n",
        "    return torch.exp(x) / torch.exp(x).sum(axis=-1,keepdims=True)\n",
        "\n",
        "def cross_entropy(output, target):#calcula la perdida de la entropia\n",
        "    logits = output[torch.arange(len(output)), target]\n",
        "    loss = - logits + torch.log(torch.sum(torch.exp(output), axis=-1))#calcular la perdida\n",
        "    loss = loss.mean()#calcular la media de la perdias\n",
        "    return loss"
      ],
      "metadata": {
        "id": "7qsC4CiK-j65"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHaWd0wvGFGH",
        "outputId": "05929444-ca28-4040-a8da-e3ee3f92e955"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 17.  10. 249. ...  -1.  -1.  -1.]\n",
            " [ 22.  17.  50. ...  -1.  -1.  -1.]\n",
            " [  8.  12. 207. ...  -1.  -1.  -1.]\n",
            " ...\n",
            " [ 14.  13. 253. ...  -1.  -1.  -1.]\n",
            " [ 10.  14. 253. ...  -1.  -1.  -1.]\n",
            " [  7.   6. 254. ...  -1.  -1.  -1.]]\n",
            "[[ 0.06666667  0.03921569  0.97647059 ... -0.00392157 -0.00392157\n",
            "  -0.00392157]\n",
            " [ 0.08627451  0.06666667  0.19607843 ... -0.00392157 -0.00392157\n",
            "  -0.00392157]\n",
            " [ 0.03137255  0.04705882  0.81176471 ... -0.00392157 -0.00392157\n",
            "  -0.00392157]\n",
            " ...\n",
            " [ 0.05882353  0.07843137  0.66666667 ... -0.00392157 -0.00392157\n",
            "  -0.00392157]\n",
            " [ 0.0627451   0.01960784  0.99215686 ... -0.00392157 -0.00392157\n",
            "  -0.00392157]\n",
            " [ 0.04313725  0.05490196  0.77254902 ... -0.00392157 -0.00392157\n",
            "  -0.00392157]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convertimos datos a tensores y copiamos en gpu\n",
        "\n",
        "#X_t = torch.from_numpy(X_train).float()\n",
        "#Y_t = torch.from_numpy(y_train).long()\n",
        "#print(X_t.shape)\n",
        "#print(Y_t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI6cs7HpDK0d",
        "outputId": "3c597352-4940-48e1-e427-ce56965119e3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7000, 784])\n",
            "torch.Size([7000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convertimos datos a tensores y copiamos en gpu\n",
        "\n",
        "X_t = torch.from_numpy(X_train).float()#los datos de entrenamiento se convierten en tensores\n",
        "Y_t = torch.from_numpy(y_train).long()#los datos de entrenamiento se convierten en tensores\n",
        "\n",
        "# bucle entrenamiento\n",
        "epochs = 150\n",
        "lr = 0.8\n",
        "log_each = 10\n",
        "l = []\n",
        "for e in range(1, epochs + 1):\n",
        "\n",
        "    # forward\n",
        "    y_pred = model(X_t)\n",
        "\n",
        "    # loss\n",
        "    loss = cross_entropy(y_pred, Y_t)\n",
        "    l.append(loss.item())\n",
        "\n",
        "    # ponemos a cero los gradientes\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Backprop (calculamos todos los gradientes automáticamente)\n",
        "    loss.backward()\n",
        "\n",
        "    # update de los pesos\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= lr * param.grad\n",
        "\n",
        "    if not e % log_each:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRiisROH-soW",
        "outputId": "066cd1f2-f7aa-4672-ac81-85f77bb42685"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/150 Loss 1.98264\n",
            "Epoch 20/150 Loss 1.97514\n",
            "Epoch 30/150 Loss 1.96813\n",
            "Epoch 40/150 Loss 1.96403\n",
            "Epoch 50/150 Loss 1.96286\n",
            "Epoch 60/150 Loss 1.96047\n",
            "Epoch 70/150 Loss 1.95868\n",
            "Epoch 80/150 Loss 1.95775\n",
            "Epoch 90/150 Loss 1.95643\n",
            "Epoch 100/150 Loss 1.95547\n",
            "Epoch 110/150 Loss 1.95474\n",
            "Epoch 120/150 Loss 1.95392\n",
            "Epoch 130/150 Loss 1.95312\n",
            "Epoch 140/150 Loss 1.95227\n",
            "Epoch 150/150 Loss 1.95163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score #libreria para calcular la precisión de las predicciones\n",
        "\n",
        "def evaluate(x):\n",
        "    model.eval()#poner el modelo en modo evaluacion\n",
        "    y_pred = model(x) # realiza una inferencia en el modelo usando el tensor de entrada X para obtenera las predicciones\n",
        "    y_probas = softmax(y_pred)#para obtener la probabilidades de clase, Convierte las puntuaciones del modelo en distribuciones de porbabilidad\n",
        "    return torch.argmax(y_probas, axis=1)#encontrar la clase con la probabilidad mas alta para cada modelo\n",
        "\n",
        "y_pred = evaluate(torch.from_numpy(X_test).float())#Realiza la evaluación del modelo en el conjunto de datos de prueba\n",
        "accuracy_score(y_test, y_pred.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_jYjE-0DX5-",
        "outputId": "8d5a943e-d38b-49ca-cdf0-2f844eee6249"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2622"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ... (entrenamiento del modelo y carga de datos)\n",
        "\n",
        "# Evaluar el modelo en el conjunto de datos de prueba\n",
        "y_pred = evaluate(torch.from_numpy(X_test).float())\n",
        "\n",
        "# Convertir las predicciones en etiquetas binarias (0 o 1)\n",
        "y_pred_binary = (y_pred > 0.5).long()\n",
        "\n",
        "# Calcular la precisión\n",
        "accuracy = accuracy_score(y_test, y_pred_binary.cpu().numpy())\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcMuCSwjEz__",
        "outputId": "1491ea82-f41e-4d76-9e7b-82b57274f99d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 15.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizador y funcion de perdida\n",
        "\n",
        "-criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "optimizador del descenso por el gradiente\n",
        "\n",
        "-optimizer = torch.optim.SGD(model.parameters(), lr=0.8)"
      ],
      "metadata": {
        "id": "4pJaql4ZWxYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()#funcion perdida\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.8)#optimizador\n",
        "\n",
        "epochs = 150\n",
        "log_each = 10\n",
        "l = []\n",
        "model.train()#poner el modelo en entrenamiento\n",
        "for e in range(1, epochs+1):\n",
        "\n",
        "    # forward\n",
        "    y_pred = model(X_t)\n",
        "\n",
        "    # loss\n",
        "    loss = criterion(y_pred, Y_t)\n",
        "    l.append(loss.item())\n",
        "\n",
        "    # ponemos a cero los gradientes\n",
        "    optimizer.zero_grad()#antes sobre el modelo ahora sobre el optimizador\n",
        "\n",
        "    # Backprop (calculamos todos los gradientes automáticamente)\n",
        "    loss.backward()\n",
        "\n",
        "    # update de los pesos\n",
        "    optimizer.step()\n",
        "\n",
        "    if not e % log_each:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n",
        "\n",
        "y_pred = evaluate(torch.from_numpy(X_test).float())\n",
        "accuracy_score(y_test, y_pred.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TzF-tfUWqYK",
        "outputId": "149d9cdb-5d29-4477-9e8a-1c1270ef3a78"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/150 Loss 2.21813\n",
            "Epoch 20/150 Loss 2.16521\n",
            "Epoch 30/150 Loss 2.12431\n",
            "Epoch 40/150 Loss 2.09428\n",
            "Epoch 50/150 Loss 2.07114\n",
            "Epoch 60/150 Loss 2.05433\n",
            "Epoch 70/150 Loss 2.04175\n",
            "Epoch 80/150 Loss 2.03191\n",
            "Epoch 90/150 Loss 2.02399\n",
            "Epoch 100/150 Loss 2.01744\n",
            "Epoch 110/150 Loss 2.01208\n",
            "Epoch 120/150 Loss 2.00751\n",
            "Epoch 130/150 Loss 2.00356\n",
            "Epoch 140/150 Loss 2.00009\n",
            "Epoch 150/150 Loss 1.99702\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2654"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}