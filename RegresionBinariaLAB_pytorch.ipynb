{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "4OggP7qtxcTy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.loadtxt(\"/content/cardiovascular_diseases_dv3.csv\", delimiter=';', skiprows=1)\n",
        "X_data = data[:, :11]\n",
        "Y_data = data[:, 11]\n",
        "print(X_data.shape)\n",
        "print(Y_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSCOtg1JxqNe",
        "outputId": "32bf8836-e919-4ad4-ceb4-f5bd681c5395"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(68783, 11)\n",
            "(68783,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_data)\n",
        "print(Y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84bOxhvYywK_",
        "outputId": "59a8582c-a3db-4167-e05a-b574c5ac0232"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 50.   2. 168. ...   0.   0.   1.]\n",
            " [ 55.   1. 156. ...   0.   0.   1.]\n",
            " [ 52.   1. 165. ...   0.   0.   0.]\n",
            " ...\n",
            " [ 52.   2. 183. ...   0.   1.   0.]\n",
            " [ 61.   1. 163. ...   0.   0.   0.]\n",
            " [ 56.   1. 170. ...   0.   0.   1.]]\n",
            "[0. 1. 1. ... 1. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_data = scaler.fit_transform(X_data)"
      ],
      "metadata": {
        "id": "hv8noZR2xvFu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convertir los datos a tensores de PyTorch\n",
        "X_train_tensor = torch.from_numpy(X_train).float()\n",
        "Y_train_tensor = torch.from_numpy(Y_train).long()# Usar LongTensor para etiquetas de clasificación binaria\n",
        "X_test_tensor = torch.from_numpy(X_test).float()\n",
        "Y_test_tensor = torch.from_numpy(Y_test).long()# Usar LongTensor para etiquetas de clasificación binaria"
      ],
      "metadata": {
        "id": "_fuEffxQx2g4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Asegurarte de que Y_train_tensor sea un tensor 1D (por ejemplo, si contiene etiquetas [0, 1, 0, 1, ...])\n",
        "Y_train_tensor = Y_train_tensor.view(-1,1)\n",
        "\n",
        "print(Y_train_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcX3_0eX3Pi3",
        "outputId": "585eea2a-e978-4719-d841-4eb218b28903"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1],\n",
            "        [1],\n",
            "        [0],\n",
            "        ...,\n",
            "        [1],\n",
            "        [0],\n",
            "        [1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir las etiquetas de entrenamiento a tipo Float\n",
        "Y_train_tensor = Y_train_tensor.float()"
      ],
      "metadata": {
        "id": "wqR4oC0o39uY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el modelo de regresión logística\n",
        "class LogisticRegressionModel(torch.nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = torch.nn.Linear(input_dim, 1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()#sigmoid que representa una decisión entre dos clases.la función sigmoide se utiliza en la capa de salida del modelo para transformar la salida en una probabilidad de pertenencia a una de las dos clases.\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "uqXwcDDSx87Q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar el modelo\n",
        "input_dim = X_train.shape[1] #numerod de columnas\n",
        "model = LogisticRegressionModel(input_dim)"
      ],
      "metadata": {
        "id": "oBVmrjr_x-8v"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la función de pérdida y el optimizador\n",
        "criterion = torch.nn.BCELoss()  # Binary Cross Entropy Loss para clasificación binaria\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)#definimos el optimizador"
      ],
      "metadata": {
        "id": "zkovTRl5yBK_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()\n",
        "#No se puede conectar con el backend de GPU\n",
        "#En estos momentos no puedes conectarte a una GPU debido a los límites de uso de Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11PWFZk9zklP",
        "outputId": "e34facc5-7e38-41c2-bd16-99f96949e225"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo\n",
        "epochs = 100\n",
        "log_each = 10\n",
        "l = []\n",
        "\n",
        "model.train()\n",
        "for e in range(1, epochs + 1):\n",
        "    # Forward\n",
        "    y_pred = model(X_train_tensor)\n",
        "    #print(y_pred)\n",
        "    # Calcular la pérdida\n",
        "    loss = criterion(y_pred, Y_train_tensor)\n",
        "    l.append(loss.item())\n",
        "\n",
        "    # Reiniciar los gradientes\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Retropropagación\n",
        "    loss.backward()\n",
        "\n",
        "    # Actualizar los pesos\n",
        "    optimizer.step()\n",
        "\n",
        "    if not e % log_each:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8esd9kUwyFBh",
        "outputId": "69b53f25-954e-4f2c-8b26-28b064064d6e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 Loss 0.72469\n",
            "Epoch 20/100 Loss 0.72406\n",
            "Epoch 30/100 Loss 0.72343\n",
            "Epoch 40/100 Loss 0.72281\n",
            "Epoch 50/100 Loss 0.72219\n",
            "Epoch 60/100 Loss 0.72158\n",
            "Epoch 70/100 Loss 0.72096\n",
            "Epoch 80/100 Loss 0.72036\n",
            "Epoch 90/100 Loss 0.71975\n",
            "Epoch 100/100 Loss 0.71915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NO PUEDO CONCECTAR CON LA GPU DEBIDO AL USO EXCESIBO\n",
        "\n",
        "from sklearn.metrics import accuracy_score #libreria para calcular la precisión de las predicciones\n",
        "def softmax(x):\n",
        "    return torch.exp(x) / torch.exp(x).sum(axis=-1,keepdims=True)\n",
        "\n",
        "\n",
        "def evaluate(x):\n",
        "    model.eval()#poner el modelo en modo evaluacion\n",
        "    y_pred = model(x) # realiza una inferencia en el modelo usando el tensor de entrada X para obtenera las predicciones\n",
        "    y_probas = softmax(y_pred)#para obtener la probabilidades de clase, Convierte las puntuaciones del modelo en distribuciones de porbabilidad\n",
        "    return torch.argmax(y_probas, axis=1)#encontrar la clase con la probabilidad mas alta para cada modelo\n",
        "\n",
        "y_pred = evaluate(torch.from_numpy(X_test).float().cuda())#Realiza la evaluación del modelo en el conjunto de datos de prueba\n",
        "accuracy_score(Y_train_tensor, y_pred.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "chX0u3ZE4LPn",
        "outputId": "337f8e5e-08cb-4329-df43-d30c6107ecbc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b9a40ca70229>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_probas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#encontrar la clase con la probabilidad mas alta para cada modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#Realiza la evaluación del modelo en el conjunto de datos de prueba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    }
  ]
}