{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p3VlVUTFcCaJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data= pd.read_csv('/content/adm_data.csv')\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNBQANlGcFL3",
        "outputId": "8a6eaa09-9bc4-4488-f998-eab8c9a42aea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400 entries, 0 to 399\n",
            "Data columns (total 9 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Serial No.         400 non-null    int64  \n",
            " 1   GRE Score          400 non-null    int64  \n",
            " 2   TOEFL Score        400 non-null    int64  \n",
            " 3   University Rating  400 non-null    int64  \n",
            " 4   SOP                400 non-null    float64\n",
            " 5   LOR                400 non-null    float64\n",
            " 6   CGPA               400 non-null    float64\n",
            " 7   Research           400 non-null    int64  \n",
            " 8   Chance of Admit    400 non-null    float64\n",
            "dtypes: float64(4), int64(5)\n",
            "memory usage: 28.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columnas_eliminar = ['Serial No.']\n",
        "data = data.drop(columnas_eliminar, axis=1)"
      ],
      "metadata": {
        "id": "ACJ1HWETcYpz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv(\"nuevodata.csv\",index=False)"
      ],
      "metadata": {
        "id": "Xg6nNvNCcjDk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.loadtxt(\"/content/nuevodata.csv\", delimiter=',',skiprows=1)\n",
        "# print(data)\n",
        "X_data = data[:, :7]\n",
        "Y_data = data[:, 7]\n",
        "print(X_data.shape)\n",
        "print(Y_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMRP23hMcmma",
        "outputId": "162701f8-2103-4f32-9d9e-d577936ac2e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400, 7)\n",
            "(400,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train=X[:13000]\n",
        "#X_test=X[13000:]\n",
        "# Calcular la media y la desviación estándar de cada característica en el conjunto de entrenamiento.\n",
        "#mean = np.mean(X_train, axis=0)\n",
        "#std = np.std(X_train, axis=0)\n",
        "# Normalizar los datos de entrenamiento.\n",
        "#X_train_normalized = (X_train - mean) / std\n",
        "# Normalizar los datos de prueba utilizando la misma media y desviación estándar.\n",
        "#X_test_normalized = (X_test - mean) / std\n",
        "\n",
        "#y_train= Y[:13000]\n",
        "#y_test= Y[13000:]\n",
        "\n",
        "\n",
        "# Normalizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_data = scaler.fit_transform(X_data)"
      ],
      "metadata": {
        "id": "dJ-jj9XXc2Qr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_t = torch.from_numpy(X_train).float().cuda()\n",
        "Y_train_t = torch.from_numpy(Y_train).float().cuda()\n",
        "X_test_t = torch.from_numpy(X_test).float().cuda()"
      ],
      "metadata": {
        "id": "o9eYYZUWc_lz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una clase personalizada para el modelo de regresión\n",
        "class ModeloRegresion(torch.nn.Module):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        super(ModeloRegresion, self).__init__()\n",
        "        self.fc1 = nn.Linear(D_in, H)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(H, D_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ICFCNw4-dFo8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir dimensiones de entrada, unidades ocultas y salida\n",
        "D_in, H, D_out = 7, 100, 1\n",
        "\n",
        "# Crear una instancia del modelo\n",
        "modelo = ModeloRegresion(D_in, H, D_out)\n",
        "\n",
        "# Mover el modelo a la GPU si está disponible\n",
        "modelo.to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAGmeCAHdIEa",
        "outputId": "69a8f10d-044b-417b-cc7f-a2a0a8e0a3cf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModeloRegresion(\n",
              "  (fc1): Linear(in_features=7, out_features=100, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=100, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la función de pérdida y el optimizador\n",
        "\n",
        "# Usar Mean Squared Error para regresión\n",
        "criterio = nn.MSELoss() # nn.MSELoss(), que es la función de pérdida de error cuadrático medio\n",
        "#criterio = nn.L1Loss() #error absoluto medio (MAE), debes cambiarla a nn.L1Loss()\n",
        "optimizador = optim.SGD(modelo.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "MJyGS4qqdOlq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo\n",
        "epochs = 100\n",
        "log_each = 10\n",
        "l = []\n",
        "\n",
        "modelo.train()\n",
        "for e in range(1, epochs + 1):\n",
        "    # Forward\n",
        "    y_pred = modelo(X_train_t)\n",
        "    #print(y_pred)\n",
        "    # Calcular la pérdida\n",
        "    loss = criterio(y_pred, Y_train_t)\n",
        "    l.append(loss.item())\n",
        "\n",
        "    # Reiniciar los gradientes\n",
        "    optimizador.zero_grad()\n",
        "\n",
        "    # Retropropagación\n",
        "    loss.backward()\n",
        "\n",
        "    # Actualizar los pesos\n",
        "    optimizador.step()\n",
        "\n",
        "    if not e % log_each:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_N_gLnSdZ0X",
        "outputId": "b0e669cd-4e0f-42ea-cf65-fe19e7bced0c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([320])) that is different to the input size (torch.Size([320, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 Loss 0.33671\n",
            "Epoch 20/100 Loss 0.29630\n",
            "Epoch 30/100 Loss 0.26427\n",
            "Epoch 40/100 Loss 0.23864\n",
            "Epoch 50/100 Loss 0.21792\n",
            "Epoch 60/100 Loss 0.20100\n",
            "Epoch 70/100 Loss 0.18704\n",
            "Epoch 80/100 Loss 0.17540\n",
            "Epoch 90/100 Loss 0.16559\n",
            "Epoch 100/100 Loss 0.15725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score #libreria para calcular la precisión de las predicciones\n",
        "from sklearn.metrics import mean_squared_error\n",
        "def softmax(x):\n",
        "    return torch.exp(x) / torch.exp(x).sum(axis=-1,keepdims=True)\n",
        "\n",
        "def evaluate(x):\n",
        "    modelo.eval()#poner el modelo en modo evaluacion\n",
        "    y_pred = modelo(x) # realiza una inferencia en el modelo usando el tensor de entrada X para obtenera las predicciones\n",
        "    y_probas = softmax(y_pred)#para obtener la probabilidades de clase, Convierte las puntuaciones del modelo en distribuciones de porbabilidad\n",
        "    return torch.argmax(y_probas, axis=1)#encontrar la clase con la probabilidad mas alta para cada modelo\n",
        "\n",
        "y_pred = evaluate(torch.from_numpy(X_test).float().cuda())#Realiza la evaluación del modelo en el conjunto de datos de prueba\n",
        "mse = mean_squared_error(Y_test, y_pred.cpu().numpy())\n",
        "print(f\"Mean Squared Error (MSE): {mse:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4fkxeqwevuY",
        "outputId": "e31e774b-5918-417c-bee0-40ce8f0ba224"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.54512\n"
          ]
        }
      ]
    }
  ]
}